use anyhow::Result;
use reqwest::Client;
use serde::{Deserialize, Serialize};
use sqlx::SqlitePool;
use std::fs::File;
use std::io::Write;

// æ•°æ®ç»“æ„å®šä¹‰
#[derive(Debug, Serialize, Deserialize, Clone, sqlx::FromRow)]
pub struct JapaneseWord {
    pub id: i64,
    pub word: String,
    pub kana: String,
    pub analysis: String,
}

#[derive(Debug, Serialize, Deserialize, Clone, sqlx::FromRow)]
pub struct JapaneseGrammar {
    pub id: i64,
    pub word: String,
    pub kana: String,
    pub analysis: String,
}

// OpenRouter API å“åº”ç»“æ„
#[derive(Debug, Deserialize)]
pub struct OpenRouterResponse {
    pub choices: Vec<Choice>,
}

#[derive(Debug, Deserialize)]
pub struct Choice {
    pub message: Message,
}

#[derive(Debug, Deserialize)]
pub struct Message {
    pub content: String,
}

#[derive(Debug, Serialize)]
pub struct OpenRouterRequest {
    pub model: String,
    pub messages: Vec<RequestMessage>,
    pub max_tokens: u32,
    pub temperature: f32,
}

#[derive(Debug, Serialize)]
pub struct RequestMessage {
    pub role: String,
    pub content: String,
}

// åˆ†æç»“æœç»“æ„
#[derive(Debug, Deserialize)]
pub struct AnalysisResult {
    pub words: Vec<WordAnalysis>,
    pub grammar: Vec<GrammarAnalysis>,
}

#[derive(Debug, Deserialize)]
pub struct WordAnalysis {
    pub word: String,
    pub kana: String,
    pub pitch: String,
    pub analysis: String,
}

#[derive(Debug, Deserialize)]
pub struct GrammarAnalysis {
    pub grammar: String,
    pub kana: String,
    pub analysis: String,
}

pub struct AnkiCreator {
    client: Client,
    pool: SqlitePool,
    api_key: String,
}

impl AnkiCreator {
    // åˆ›å»ºæ–°å®ä¾‹
    pub async fn new(api_key: String) -> Result<Self> {
        let client = Client::new();
        let pool = SqlitePool::connect("sqlite:anki_cards.db").await?;
        
        // åˆå§‹åŒ–æ•°æ®åº“è¡¨
        sqlx::query(
            r#"
            CREATE TABLE IF NOT EXISTS words (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                word TEXT NOT NULL UNIQUE,
                kana TEXT NOT NULL,
                analysis TEXT NOT NULL,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
            "#
        ).execute(&pool).await?;

        sqlx::query(
            r#"
            CREATE TABLE IF NOT EXISTS grammar (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                word TEXT NOT NULL UNIQUE,
                kana TEXT NOT NULL,
                analysis TEXT NOT NULL,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
            "#
        ).execute(&pool).await?;

        Ok(AnkiCreator {
            client,
            pool,
            api_key,
        })
    }

    // è°ƒç”¨ OpenRouter API åˆ†ææ—¥è¯­æ–‡æœ¬
    pub async fn analyze_japanese_text(&self, text: &str) -> Result<String> {
        let prompt = format!(r#"
è¯·åˆ†æä»¥ä¸‹æ—¥è¯­æ–‡æœ¬ï¼Œæå–å‡ºæ‰€æœ‰å•è¯å’Œè¯­æ³•ç‚¹ã€‚è¦æ±‚ï¼š

1. å•è¯éƒ¨åˆ†ï¼š
   - å°†æ‰€æœ‰å•è¯è½¬æ¢ä¸ºè¾ä¹¦å½¢ï¼ˆåŸå½¢ï¼‰
   - æä¾›å‡åè¯»éŸ³
   - æä¾›éŸ³è°ƒï¼ˆç”¨0-4æ•°å­—è¡¨ç¤ºï¼‰
   - æä¾›ä¸­æ–‡è§£é‡Š

2. è¯­æ³•éƒ¨åˆ†ï¼š
   - è¯†åˆ«è¯­æ³•ç»“æ„å’Œè¡¨è¾¾æ–¹å¼
   - æä¾›å‡åè¯»éŸ³
   - æä¾›ä¸­æ–‡è§£é‡Šå’Œç”¨æ³•

è¯·ç”¨ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼š
{{
  "words": [
    {{
      "word": "å˜è¯­è¾ä¹¦å½¢",
      "kana": "ã‹ãª",
      "pitch": "0", 
      "analysis": "ä¸­æ–‡è§£é‡Šå’Œè¯¦ç»†åˆ†æ"
    }}
  ],
  "grammar": [
    {{
      "grammar": "è¯­æ³•è¡¨è¾¾",
      "kana": "ã‹ãª",
      "analysis": "è¯­æ³•è§£é‡Šå’Œç”¨æ³•è¯´æ˜"
    }}
  ]
}}

è¦åˆ†æçš„æ–‡æœ¬ï¼š
{}
"#, text);

        let request = OpenRouterRequest {
            model: "google/gemini-2.5-flash".to_string(),
            messages: vec![RequestMessage {
                role: "user".to_string(),
                content: prompt,
            }],
            max_tokens: 4000,
            temperature: 0.1,
        };

        let response = self.client
            .post("https://openrouter.ai/api/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .json(&request)
            .send()
            .await?;

        if !response.status().is_success() {
            let error_text = response.text().await?;
            anyhow::bail!("API è¯·æ±‚å¤±è´¥: {}", error_text);
        }

        let api_response: OpenRouterResponse = response.json().await?;
        let content = &api_response.choices[0].message.content;
        
        // æå–JSONéƒ¨åˆ†
        let json_start = content.find('{').unwrap_or(0);
        let json_end = content.rfind('}').map(|i| i + 1).unwrap_or(content.len());
        let json_content = &content[json_start..json_end];
        
        Ok(json_content.to_string())
    }

    // ä¿å­˜å•è¯åˆ°æ•°æ®åº“
    pub async fn save_words(&self, words: &[WordAnalysis]) -> Result<()> {
        for word in words {
            let analysis_with_pitch = format!("{} [éŸ³è°ƒ: {}]", word.analysis, word.pitch);
            
            sqlx::query(
                "INSERT OR REPLACE INTO words (word, kana, analysis) VALUES (?, ?, ?)"
            )
            .bind(&word.word)
            .bind(&word.kana)
            .bind(&analysis_with_pitch)
            .execute(&self.pool)
            .await?;
        }
        Ok(())
    }

    // ä¿å­˜è¯­æ³•åˆ°æ•°æ®åº“
    pub async fn save_grammar(&self, grammar: &[GrammarAnalysis]) -> Result<()> {
        for item in grammar {
            sqlx::query(
                "INSERT OR REPLACE INTO grammar (word, kana, analysis) VALUES (?, ?, ?)"
            )
            .bind(&item.grammar)
            .bind(&item.kana)
            .bind(&item.analysis)
            .execute(&self.pool)
            .await?;
        }
        Ok(())
    }

    // ç”Ÿæˆå•è¯ Anki å¡ç‰‡
    pub async fn generate_word_cards(&self) -> Result<()> {
        let words = sqlx::query_as::<_, JapaneseWord>(
            "SELECT id, word, kana, analysis FROM words ORDER BY id"
        ).fetch_all(&self.pool).await?;

        let mut file = File::create("japanese_words.csv")?;
        
        // å†™å…¥ CSV å¤´éƒ¨ï¼ˆå¸¦æœ‰ ID å­—æ®µï¼‰
        writeln!(file, "id,word,kana,analysis")?;
        
        for word in words {
            // CSV æ ¼å¼ï¼Œç¡®ä¿ ID åœ¨ç¬¬ä¸€ä¸ªå­—æ®µ
            writeln!(file, "{},\"{}\",\"{}\",\"{}\"", 
                word.id, 
                word.word.replace("\"", "\"\""),
                word.kana.replace("\"", "\"\""),
                word.analysis.replace("\"", "\"\"")
            )?;
        }
        
        println!("âœ… å•è¯å¡ç‰‡å·²ç”Ÿæˆï¼šjapanese_words.csv");
        Ok(())
    }

    // ç”Ÿæˆè¯­æ³• Anki å¡ç‰‡  
    pub async fn generate_grammar_cards(&self) -> Result<()> {
        let grammar = sqlx::query_as::<_, JapaneseGrammar>(
            "SELECT id, word, kana, analysis FROM grammar ORDER BY id"
        ).fetch_all(&self.pool).await?;

        let mut file = File::create("japanese_grammar.csv")?;
        
        // å†™å…¥ CSV å¤´éƒ¨ï¼ˆå¸¦æœ‰ ID å­—æ®µï¼‰
        writeln!(file, "id,grammar,kana,analysis")?;
        
        for item in grammar {
            // CSV æ ¼å¼ï¼Œç¡®ä¿ ID åœ¨ç¬¬ä¸€ä¸ªå­—æ®µ
            writeln!(file, "{},\"{}\",\"{}\",\"{}\"", 
                item.id, 
                item.word.replace("\"", "\"\""),
                item.kana.replace("\"", "\"\""),
                item.analysis.replace("\"", "\"\"")
            )?;
        }
        
        println!("âœ… è¯­æ³•å¡ç‰‡å·²ç”Ÿæˆï¼šjapanese_grammar.csv");
        Ok(())
    }

    // å¤„ç†æ—¥è¯­æ–‡æœ¬çš„ä¸»è¦å‡½æ•°
    pub async fn process_japanese_text(&self, text: &str) -> Result<()> {
        println!("ğŸ”„ å¼€å§‹åˆ†ææ—¥è¯­æ–‡æœ¬...");
        
        // è°ƒç”¨ API åˆ†ææ–‡æœ¬
        let json_response = self.analyze_japanese_text(text).await?;
        
        // è§£æ JSON å“åº”
        let analysis: AnalysisResult = serde_json::from_str(&json_response)
            .map_err(|e| anyhow::anyhow!("è§£æ API å“åº”å¤±è´¥: {}\nå“åº”å†…å®¹: {}", e, json_response))?;

        println!("ğŸ“ æ‰¾åˆ° {} ä¸ªå•è¯ï¼Œ{} ä¸ªè¯­æ³•ç‚¹", 
            analysis.words.len(), 
            analysis.grammar.len()
        );

        // ä¿å­˜åˆ°æ•°æ®åº“
        self.save_words(&analysis.words).await?;
        self.save_grammar(&analysis.grammar).await?;
        
        println!("ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°æ•°æ®åº“");

        // ç”Ÿæˆ Anki å¡ç‰‡
        self.generate_word_cards().await?;
        self.generate_grammar_cards().await?;
        
        Ok(())
    }
}

#[tokio::main]
async fn main() -> Result<()> {
    println!("ğŸŒ æ—¥è¯­ Anki å¡ç‰‡ç”Ÿæˆå™¨");
    
    // ä»ç¯å¢ƒå˜é‡è·å– API å¯†é’¥
    let api_key = std::env::var("OPENROUTER_API_KEY")
        .unwrap_or_else(|_| {
            println!("âš ï¸  è¯·è®¾ç½® OPENROUTER_API_KEY ç¯å¢ƒå˜é‡");
            println!("   export OPENROUTER_API_KEY=your_api_key");
            std::process::exit(1);
        });

    // åˆ›å»º Anki å¡ç‰‡ç”Ÿæˆå™¨
    let creator = AnkiCreator::new(api_key).await?;
    
    // ç¤ºä¾‹æ—¥è¯­æ–‡æœ¬ï¼ˆå¯ä»¥ä¿®æ”¹ä¸ºä½ æƒ³è¦çš„æ–‡æœ¬ï¼‰
    let sample_text = r#"
ä»Šæ—¥ã¯è‰¯ã„å¤©æ°—ã§ã™ã­ã€‚å…¬åœ’ã«æ•£æ­©ã—ã«è¡Œãã¾ã—ã‚‡ã†ã€‚
æ¡œãŒæº€é–‹ã§ã€ã¨ã¦ã‚‚ç¾ã—ã„ã§ã™ã€‚å†™çœŸã‚’æ’®ã‚ŠãŸã„ã¨æ€ã„ã¾ã™ã€‚
æ—¥æœ¬èªã‚’å‹‰å¼·ã™ã‚‹ã®ã¯æ¥½ã—ã„ã§ã™ãŒã€æ™‚ã€…é›£ã—ã„ã§ã™ã€‚
"#;

    println!("ğŸ“– å¤„ç†ç¤ºä¾‹æ–‡æœ¬...");
    println!("æ–‡æœ¬å†…å®¹: {}", sample_text);
    
    // å¤„ç†æ–‡æœ¬
    creator.process_japanese_text(sample_text).await?;
    
    println!("\nğŸ‰ å®Œæˆï¼ç”Ÿæˆçš„æ–‡ä»¶ï¼š");
    println!("   ğŸ“„ japanese_words.csv - å•è¯å¡ç‰‡");
    println!("   ğŸ“„ japanese_grammar.csv - è¯­æ³•å¡ç‰‡");
    println!("   ğŸ—„ï¸  anki_cards.db - SQLite æ•°æ®åº“");
    
    println!("\nğŸ“‹ ä½¿ç”¨è¯´æ˜ï¼š");
    println!("1. åœ¨ Anki ä¸­å¯¼å…¥ CSV æ–‡ä»¶");
    println!("2. ç¡®ä¿å­—æ®µæ˜ å°„æ­£ç¡®ï¼ˆID å­—æ®µç”¨äºæ›´æ–°ç°æœ‰å¡ç‰‡ï¼‰");
    println!("3. å•è¯å’Œè¯­æ³•ä¼šåˆ›å»ºä¸ºä¸åŒçš„å¡ç»„");
    
    Ok(())
}
